{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Detector Demonstration (Sentiment Classification)\n",
    "This model performs spam detection on emails, classifying them as spam or not spam.\n",
    "\n",
    "Dataset from Kaggle: https://www.kaggle.com/datasets/nitishabharathi/email-spam-dataset\n",
    "\n",
    "Contact: rohan11parekh@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting Pytorch device\n",
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Loading the csv into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/Emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nSave up to 70% on Life Insurance.\\nWhy Spend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>##############################################...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I thought you might like these:\\n1) Slim Down ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Body  Label\n",
       "0           0  \\nSave up to 70% on Life Insurance.\\nWhy Spend...      1\n",
       "1           1  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
       "2           2  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
       "3           3  ##############################################...      1\n",
       "4           4  I thought you might like these:\\n1) Slim Down ...      1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the ratio of spam to non-spam emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam: 1896\n",
      "Not spam: 4150\n"
     ]
    }
   ],
   "source": [
    "print(\"Spam:\", data['Label'].value_counts()[1] )\n",
    "print(\"Not spam:\", data['Label'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 1 = spam, 0 = legit\n",
    "\n",
    "Cleaning the dataset of unused columns, null values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nSave up to 70% on Life Insurance.\\nWhy Spend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>##############################################...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I thought you might like these:\\n1) Slim Down ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Body  Label\n",
       "0           0  \\nSave up to 70% on Life Insurance.\\nWhy Spend...      1\n",
       "1           1  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
       "2           2  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
       "3           3  ##############################################...      1\n",
       "4           4  I thought you might like these:\\n1) Slim Down ...      1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_to_remove = 'empty'\n",
    "df = data[~data.apply(lambda row: value_to_remove in row.values, axis=1)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3676</td>\n",
       "      <td>use Perl Daily Headline MailerThis Week on per...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1422</td>\n",
       "      <td>Easy to make \"Between $200,000 and $500,000 ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4170</td>\n",
       "      <td>URL: http://www.newsisfree.com/click/-5,855353...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5924</td>\n",
       "      <td>\\nBuyer's Alert | July 18, 2002When ordering, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5773</td>\n",
       "      <td>\\nForwarded-by: Nev Dull \\nForwarded-by: \"Simo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Body  Label\n",
       "0        3676  use Perl Daily Headline MailerThis Week on per...      0\n",
       "1        1422  Easy to make \"Between $200,000 and $500,000 ev...      1\n",
       "2        4170  URL: http://www.newsisfree.com/click/-5,855353...      0\n",
       "3        5924  \\nBuyer's Alert | July 18, 2002When ordering, ...      0\n",
       "4        5773  \\nForwarded-by: Nev Dull \\nForwarded-by: \"Simo...      0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam: 1561\n",
      "Not spam: 3952\n"
     ]
    }
   ],
   "source": [
    "print(\"Spam:\", df['Label'].value_counts()[1])\n",
    "print(\"Not spam:\", df['Label'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'use Perl Daily Headline MailerThis Week on perl5-porters (2-8 September 2002)\\n    posted by rafael on Monday September 09, @07:33 (summaries)\\n    http://use.perl.org/article.pl?sid=02/09/09/1147243\\nCopyright 1997-2002 pudge.  All rights reserved.\\n======================================================================You have received this message because you subscribed to it\\non use Perl.  To stop receiving this and other\\nmessages from use Perl, or to add more messages\\nor change your preferences, please go to your user page.\\thttp://use.perl.org/my/messages/You can log in and change your preferences from there.\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df['Body'].to_list()\n",
    "emails = np.array(temp)\n",
    "emails[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining methods to clean emails of stopwords, punctuation, etc. and tokenizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.encode('utf-8', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    # Using RegEx to remove URLs, punctuation, newline characters\n",
    "    out = re.sub(r'(https?://\\S+|www\\.\\S+)|[^a-zA-Z\\s]', ' ', text)\n",
    "    out = out.lower()\n",
    "    out = \" \".join(out.split())\n",
    "    \n",
    "    # Tokenize and remove stop words\n",
    "    word_tokens = word_tokenize(out)\n",
    "    output = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    return output\n",
    "\n",
    "def clean_list(s):\n",
    "    out = []\n",
    "    for item in s:\n",
    "        out.append(clean(item))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['winner',\n",
       " 'dear',\n",
       " 'traveler',\n",
       " 'congratulations',\n",
       " 'may',\n",
       " 'one',\n",
       " 'lucky',\n",
       " 'winners',\n",
       " 'may',\n",
       " 'spending']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_emails = clean_list(emails)\n",
    "cleaned_emails[30][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a vocabulary of all words and their frequencies using Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(email_list):\n",
    "    count = Counter()\n",
    "    for email in email_list:\n",
    "        for word in email:\n",
    "            count[word.lower()] += 1\n",
    "    return count\n",
    "\n",
    "word_dict = count_words(cleaned_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing variables for memory\n",
    "del stop_words\n",
    "del stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pretrained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word_to_index = {\"<UNK>\": 0, **{word: idx + 1 for idx, word in enumerate(word_dict.keys())}}\n",
    "\n",
    "word2vec_path = 'GoogleNews-vectors-negative300.bin'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding matrix with Word2Vec vectors or random vectors\n",
    "embedding_dim = 300 \n",
    "\n",
    "vocab_size = len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60691"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding matrix with random values\n",
    "embedding_matrix = np.random.normal(0, 1, (vocab_size, embedding_dim))\n",
    "\n",
    "# Fill embedding matrix with Word2Vec embeddings\n",
    "for word, idx in word_to_index.items():\n",
    "    if word in word2vec:\n",
    "        embedding_matrix[idx] = word2vec[word]\n",
    "    else:\n",
    "        embedding_matrix[idx] = np.random.normal(0, 1, embedding_dim)  # For unknown words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embedding matrix to PyTorch tensor\n",
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1238, -0.1111,  1.4762, -2.3536, -1.6161,  0.3414, -0.3679, -2.2525,\n",
       "        -0.4218,  1.8223, -0.5226,  0.1847,  0.7273,  0.8440,  2.3363, -0.3953,\n",
       "         0.3349, -0.7453, -0.4501, -2.7956,  1.4428,  0.1992, -1.3935,  0.7688,\n",
       "        -0.6857, -0.0527,  0.6928, -0.5977,  0.9287, -1.4980,  0.3672, -0.9094,\n",
       "         0.7140, -0.2357, -0.5076, -1.1802,  0.1182, -1.5683,  0.0143,  2.5732,\n",
       "        -0.6733, -1.8206, -1.0340,  0.0183,  0.1113,  0.0449, -0.2892, -0.1344,\n",
       "        -0.5470, -0.8952,  0.3009,  1.7594,  1.1873, -0.9170, -2.3336, -1.0710,\n",
       "         1.4270, -0.0797, -0.2102,  1.2017, -0.5514,  2.0145,  0.0673, -0.2513,\n",
       "        -0.3447,  0.8609,  0.5684, -0.6716,  0.7632, -0.7360, -0.3928, -1.2352,\n",
       "         0.5281, -0.3512,  0.8552, -2.3752, -1.6317,  1.0024,  0.4473,  0.4650,\n",
       "        -0.3945, -0.1444,  0.5996, -0.3501,  0.1139, -0.6309, -0.7605,  1.1564,\n",
       "         0.1849,  2.3943, -0.1983,  0.3115,  0.1366, -1.1992,  0.8544, -0.2485,\n",
       "         1.0890,  0.9571, -0.9503,  0.5309])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounting for unknown words\n",
    "from collections import defaultdict\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "vocab = defaultdict(lambda: len(vocab))\n",
    "UNK = vocab[\"<UNK>\"]\n",
    "\n",
    "for text in cleaned_emails:\n",
    "    for word in text:\n",
    "        _ = vocab[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the text needs to be converting into tensors so they can be fed into the model. To do this I define a method called text_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tensor(text):\n",
    "    indices = [vocab.get(word, UNK) for word in text]  # Convert words to indices\n",
    "    return torch.tensor(indices, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  2,  7,  8,  9, 10, 11,  8, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19,  1,  2, 20, 21, 22,  1,  2, 23, 22, 24, 25, 26, 27, 28, 29,\n",
       "        30, 24, 25])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tensor = []\n",
    "for text in cleaned_emails:\n",
    "    temp_tensor.append(text_to_tensor(text))\n",
    "temp_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the train and test sets so all the inputs are equal length \n",
    "emails_pad = [(seq[:500]) for seq in temp_tensor]\n",
    "emails_pad = pad_sequence(emails_pad, batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing memory\n",
    "del cleaned_emails\n",
    "del data\n",
    "del temp\n",
    "del temp_tensor\n",
    "del word_to_index\n",
    "del vocab\n",
    "del text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5513"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emails_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(df['Label'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5513"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is in a readable format, it can be split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Parekh\\AppData\\Local\\Temp\\ipykernel_21696\\4052473518.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(emails_pad.clone().detach()[:5250])\n",
      "C:\\Users\\Rohan Parekh\\AppData\\Local\\Temp\\ipykernel_21696\\4052473518.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(emails_pad.clone().detach()[5250:])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(emails_pad.clone().detach()[:5250])\n",
    "X_test = torch.tensor(emails_pad.clone().detach()[5250:])\n",
    "Y_train = torch.tensor(labels[:5250])\n",
    "Y_test = torch.tensor(labels[5250:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5250, 500])\n",
      "torch.Size([5250])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5513,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Dataloaders\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader\n",
    "train = data_utils.TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "test = data_utils.TensorDataset(X_test, Y_test)\n",
    "test_loader = DataLoader(test, batch_size=16, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('list', 4431), ('one', 3907), ('e', 3779), ('get', 3697), ('email', 3585)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing the top 5 most common words\n",
    "word_dict.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class SpamDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpamDetector, self).__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        self.LSTM = nn.LSTM(300, 200, batch_first=True)\n",
    "        self.LSTM2 = nn.LSTM(200, 300, batch_first=True)\n",
    "        self.fc1 = nn.Linear(300, 1000)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1000, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x, _ = self.LSTM(x)\n",
    "        x, _ = self.LSTM2(x)\n",
    "        x = x[:, -1, :]  # Taking the last hidden state\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x) \n",
    "        return x\n",
    "    # I don't return it with sigmoid because BCEWithLogitsLoss expects raw logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing memory\n",
    "del df\n",
    "del test\n",
    "del train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop (10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Parekh\\AppData\\Local\\Temp\\ipykernel_21696\\768564030.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = torch.tensor((outputs[:, 0].clone().detach() >= 0.5).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2886, Accuracy: 79.89%\n",
      "Epoch [2/10], Loss: 0.1514, Accuracy: 97.33%\n",
      "Epoch [3/10], Loss: 0.2210, Accuracy: 98.11%\n",
      "Epoch [4/10], Loss: 2.0757, Accuracy: 96.78%\n",
      "Epoch [5/10], Loss: 1.0634, Accuracy: 96.10%\n",
      "Epoch [6/10], Loss: 0.4247, Accuracy: 98.19%\n",
      "Epoch [7/10], Loss: 0.4943, Accuracy: 97.85%\n",
      "Epoch [8/10], Loss: 0.4954, Accuracy: 98.10%\n",
      "Epoch [9/10], Loss: 0.3628, Accuracy: 98.88%\n",
      "Epoch [10/10], Loss: 0.3679, Accuracy: 99.20%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Model, Loss Function, and Optimizer\n",
    "model = SpamDetector().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([4150/1896]).to(device)) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    accuracy = 0\n",
    "    avg_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.float()\n",
    "        # Forward Pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs[:,0], labels)\n",
    "        \n",
    "        # Backward and Optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get predictions and compute accuracy\n",
    "        outputs = torch.tensor((outputs[:, 0].clone().detach() >= 0.5).float())\n",
    "        total += labels.size(0)  # Total number of labels\n",
    "        correct += (outputs == labels).sum().item()  # Count correct predictions\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        \n",
    "    # Calculate and print the average loss and accuracy for the epoch\n",
    "    avg_loss /= len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running model on test set\n",
    "Outputs printed for proof. Note: You will have to scroll a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Predicted: 0.0 | Actual: 0.0\n",
      "Predicted: 1.0 | Actual: 1.0\n",
      "Accuracy on test set: 98.44%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on Test Data\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to device\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        labels = labels.float()\n",
    "        # Move tensors to CPU and convert to numpy arrays\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        predictions = [1.0 if value >= 0.5 else 0.0 for value in outputs]\n",
    "\n",
    "        total += labels.shape[0]\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        \n",
    "        # Iterate over each sample in the batch\n",
    "        for i in range(len(predictions)):\n",
    "            print(f'Predicted: {predictions[i]} | Actual: {labels[i]}')\n",
    "\n",
    "print(f'Accuracy on test set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying two individual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snoring problems? Let Snore\n",
      "Eliminator's all natural ingredients help you\n",
      "sleep!Â Â Â Â Â Â  1r\n",
      "Is snoring\n",
      "keeping you up all night? No\n",
      "more sleepless nights with\n",
      "Snore Eliminator!!\n",
      "Let your family sleep again by using the Snore Eliminator!\n",
      "Do you know someone with a snoring problem? Snore Eliminator will help them\n",
      "and they will love you for it.\n",
      "Improve your sexual performance by reducing snoring and thus increasing\n",
      "oxygen to your body!!People who snore have a higher risk of developing heart attacks, high blood\n",
      "pressure, or strokes!! Snoring\n",
      "also causes sleep disturbances that lead to increased anxiety,\n",
      "...",
      "\n",
      "Predicted class: 1.0\n",
      "Actual class:  1.0\n"
     ]
    }
   ],
   "source": [
    "emails_pad = emails_pad.to(device)\n",
    "with torch.no_grad():\n",
    "    out = model(emails_pad[12].unsqueeze(0))\n",
    "    predicted_class = torch.round(torch.sigmoid(out)) \n",
    "    print(emails[12]) # Printing first spam email without fishy links for safety\n",
    "    print(\"Predicted class:\", predicted_class.item())\n",
    "    print(\"Actual class: \", labels[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: http://www.newsisfree.com/click/-5,8553538,1440/\n",
      "Date: Not suppliedViral antibodies are identified in a one-month-old baby, as the US death toll \n",
      "rises sharply\n",
      "\n",
      "Predicted class: 0.0\n",
      "Actual class:  0.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(emails_pad[2].unsqueeze(0))\n",
    "    predicted_class = torch.round(torch.sigmoid(out))  \n",
    "    print(emails[2]) # First non-spam email \n",
    "    print(\"Predicted class:\", predicted_class.item())\n",
    "    print(\"Actual class: \", labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email: rohan11parekh@gmail.com \n",
    "\n",
    "### LinkedIn: https://www.linkedin.com/in/rohan-parekh-39b070225/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
